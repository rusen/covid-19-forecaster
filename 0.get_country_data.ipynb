{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./data'):\n",
    "    shutil.rmtree('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the relevant statistics\n",
    "!git clone https://github.com/CSSEGISandData/COVID-19.git data/COVID-19\n",
    "!git clone https://github.com/datasets/population.git data/population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "lookahead = 8 # Lookahead weeks. Set to 8 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded paths\n",
    "population_csv = './data/population/data/population.csv'\n",
    "confirmed_csv = './data/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important dates\n",
    "begin_date_str = '1/27/20' # Make sure it's a monday, and the day before exists in the data\n",
    "begin_date = datetime.datetime.strptime(begin_date_str, \"%m/%d/%y\").date()\n",
    "print(f'Begin date : {begin_date_str}')\n",
    "\n",
    "today = datetime.date.today()\n",
    "today_date = f'{today.month}/{today.day}/{today.year-2000}'\n",
    "print(f'Date today : {today_date}')\n",
    "\n",
    "end_date = today - datetime.timedelta(today.weekday()+1)\n",
    "end_date_str = f'{end_date.month}/{end_date.day}/{end_date.year-2000}'\n",
    "print(f'End of last week : {end_date_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "week_begin = today - datetime.timedelta(today.weekday())\n",
    "week_end = week_begin + datetime.timedelta(days=6)\n",
    "cur_week_name = f'{week_begin.month}-{week_begin.day}-{week_begin.year-2000}-to-{week_end.month}-{week_end.day}-{week_end.year-2000}'\n",
    "preds_folder = f'./preds/weekly/{cur_week_name}'\n",
    "output_folder = f'./output/weekly/{cur_week_name}'\n",
    "print(f'Current identifier: *{cur_week_name}*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate existing prediction folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(preds_folder):\n",
    "    shutil.rmtree(preds_folder)\n",
    "os.makedirs(preds_folder)\n",
    "print(preds_folder)\n",
    "\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "os.makedirs(output_folder)\n",
    "print(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from locally downloaded datasets and pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_case_country_names = {\n",
    "    'Taiwan*': 'Taiwan',\n",
    "    'Congo (Brazzaville)': 'Congo, Rep.',\n",
    "    'Congo (Kinshasa)': 'Congo, Dem. Rep.',\n",
    "    'Bahamas': 'Bahamas, The',\n",
    "    'Czechia': 'Czech Republic',\n",
    "    'US': 'United States',\n",
    "}\n",
    "\n",
    "fix_country_names = {\n",
    "    'Brunei Darussalam': 'Brunei',\n",
    "    'Egypt, Arab Rep.': 'Egypt',\n",
    "    'Gambia, The': 'Gambia',\n",
    "    'Iran, Islamic Rep.': 'Iran',\n",
    "    'Korea, Rep.': 'Korea, South',\n",
    "    'Russian Federation': 'Russia',\n",
    "    'St. Kitts and Nevis': 'Saint Kitts and Nevis',\n",
    "    'St. Lucia': 'Saint Lucia',\n",
    "    'St. Vincent and the Grenadines': 'Saint Vincent and the Grenadines',\n",
    "    'Syrian Arab Republic': 'Syria',\n",
    "    'Venezuela, RB': 'Venezuela',\n",
    "    'Yemen, Rep.': 'Yemen',\n",
    "    'Kyrgyz Republic': 'Kyrgyzstan'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Covid data\n",
    "df = pd.read_csv(confirmed_csv)\n",
    "last_col = df.columns[-1]\n",
    "df = df.rename(columns={'Country/Region':'Country'})\n",
    "df = df.sort_values(['Country', last_col], ascending=[True, True])\n",
    "df = df.drop_duplicates(['Country'], 'last')\n",
    "df = df.drop(columns=['Province/State', 'Lat', 'Long']).reset_index(drop=True)\n",
    "\n",
    "# Get day columns\n",
    "day_cols = []\n",
    "cur_date = begin_date - datetime.timedelta(1)\n",
    "while cur_date <= end_date:\n",
    "    cur_date_str = f'{cur_date.month}/{cur_date.day}/{cur_date.year-2000}'\n",
    "    day_cols.append(cur_date_str)\n",
    "    cur_date += datetime.timedelta(1)\n",
    "\n",
    "# Get daily numbers\n",
    "day_idx = day_cols.index(begin_date_str) - 1\n",
    "day_cols = day_cols[day_idx:]\n",
    "cum_df = deepcopy(df[day_cols])\n",
    "for col_itr in range(1, len(day_cols)):\n",
    "    df[day_cols[col_itr]] = np.maximum(0, cum_df[day_cols[col_itr]] - cum_df[day_cols[col_itr-1]])\n",
    "    \n",
    "# Remove the first day (it is a Sunday!)\n",
    "day_cols = day_cols[1:]\n",
    "    \n",
    "# Fix the actual names to be used\n",
    "for itr in range(len(df)):\n",
    "    existing_name = df.loc[itr, 'Country']\n",
    "    df.loc[itr, 'Country'] = fix_case_country_names[existing_name] if existing_name in fix_case_country_names else existing_name\n",
    "\n",
    "print(len(df))\n",
    "display(df.tail(3))\n",
    "df_cases = deepcopy(df)\n",
    "\n",
    "# Population data\n",
    "df_pop = pd.read_csv(population_csv)\n",
    "df_pop = df_pop.sort_values(['Country Name', 'Year'], ascending=[True, True])\n",
    "df_pop = df_pop.drop_duplicates(subset=['Country Name'], keep='last').reset_index(drop=True)\n",
    "df_pop = df_pop.rename(columns={'Country Name':'Country', 'Country Code': 'CCODE', 'Value':'Population'})[['Country', 'CCODE', 'Population']].reset_index(drop=True)\n",
    "df_pop.loc[len(df_pop)] = ['Taiwan', 'TWN', 22894384]\n",
    "df_pop.loc[len(df_pop)] = ['Slovakia', 'SVK', 5455000]\n",
    "for itr in range(len(df_pop)):\n",
    "    existing_name = df_pop.loc[itr, 'Country']\n",
    "    df_pop.loc[itr, 'Country'] = fix_country_names[existing_name] if existing_name in fix_country_names else existing_name\n",
    "print(len(df_pop))\n",
    "display(df_pop.tail(3))\n",
    "\n",
    "# Join both\n",
    "df = df.merge(df_pop, on='Country').reset_index(drop=True)\n",
    "df['is_country'] = 1\n",
    "df['Lat'] = -1\n",
    "df['Lon'] = -1\n",
    "df['Name'] = df['Country']\n",
    "base_cols = ['Name', 'Country', 'is_country', 'CCODE', 'Population', 'Lat', 'Lon']\n",
    "df = df[base_cols + day_cols]\n",
    "\n",
    "print(len(df))\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We are skipping the following \"countries\" which have cases in the dataset but they don't exist in population dataset\n",
    "set(df_cases['Country'].values) - set(df['Name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide numbers by population and drop population column\n",
    "for day in day_cols:\n",
    "    df[day] = df[day] / df['Population']\n",
    "df = df.drop(columns=['Population'])\n",
    "base_cols = [x for x in base_cols if x != 'Population']\n",
    "base_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{output_folder}/country_daily.csv\")\n",
    "\n",
    "# Write individual predictions to file\n",
    "cols = {\n",
    "    'base_cols': base_cols,\n",
    "    'day_cols': day_cols,\n",
    "}\n",
    "with open(f\"{output_folder}/cols.pkl\",\"wb\") as f:\n",
    "    pickle.dump(cols,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
