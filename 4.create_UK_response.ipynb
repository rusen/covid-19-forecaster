{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the following environment variable is set! \n",
    "creds_path = os.environ['GOOGLE_APPLICATION_CREDENTIALS_PATH']\n",
    "gcs_client = storage.Client.from_service_account_json(creds_path)\n",
    "bucket = gcs_client.get_bucket('covid-19-forecaster-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "begin_date_str = '1/27/20' # Make sure it's a monday, and the day before exists in the data\n",
    "begin_date = datetime.datetime.strptime(begin_date_str, \"%m/%d/%y\")\n",
    "\n",
    "today = datetime.date.today()\n",
    "today_date = f'{today.month}/{today.day}/{today.year-2000}'\n",
    "today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded paths and values\n",
    "travel_advice_pre_url = 'https://www.gov.uk/foreign-travel-advice'\n",
    "travel_advice_url = \"https://www.gov.uk/guidance/coronavirus-covid-19-travel-corridors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "week_begin = today - datetime.timedelta(today.weekday())\n",
    "week_end = week_begin + datetime.timedelta(days=6)\n",
    "cur_week_name = f'{week_begin.month}-{week_begin.day}-{week_begin.year-2000}-to-{week_end.month}-{week_end.day}-{week_end.year-2000}'\n",
    "output_folder = f'./preds/weekly/{cur_week_name}'\n",
    "print(f'Current identifier: *{cur_week_name}*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(f'./output/weekly/{cur_week_name}/df_final.csv', index_col=0)\n",
    "with open(f\"./output/weekly/{cur_week_name}/config.pkl\",\"rb\") as f:\n",
    "    config = pickle.load(f)\n",
    "with open(f\"./output/weekly/{cur_week_name}/all_preds.pkl\",\"rb\") as f:\n",
    "    pred_weeks_data = pickle.load(f)\n",
    "with open(f\"./output/weekly/{cur_week_name}/risk_preds.pkl\",\"rb\") as f:\n",
    "    risk_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, calculate restriction likelihood for last week, along with future weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weeks = config['week_names'][-config['lookahead']:]\n",
    "last_week_name = config['week_names'][-(config['lookahead']+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weeks_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK-based limit is 20 in 100k, we don't need to learn it\n",
    "category_limits = [[-np.inf, 0.00020], [0.00020, np.inf]]\n",
    "confidence_limits = [[0, 95], [95, 100], [100, np.inf]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category-based predictions and confidence values\n",
    "\n",
    "# Start with last week\n",
    "last_week_data = df_final[last_week_name].values\n",
    "last_week_category_preds = last_week_data.copy()\n",
    "for category in range(len(category_limits)):\n",
    "    last_week_category_preds[(last_week_data < category_limits[category][1]) & \\\n",
    "                             (last_week_data >= category_limits[category][0])] = category\n",
    "\n",
    "# Get category prediction for every predicted scenario\n",
    "category_counts = pred_weeks_data.copy()\n",
    "for category in range(len(category_limits)):\n",
    "    category_counts[(pred_weeks_data < category_limits[category][1]) & \\\n",
    "                    (pred_weeks_data >= category_limits[category][0])] = category\n",
    "    \n",
    "# Get singular predictions and confidence.\n",
    "mode = stats.mode(category_counts, axis=2)\n",
    "category_preds = mode.mode.squeeze()\n",
    "category_preds = category_preds\n",
    "\n",
    "# Calculate confidence\n",
    "category_probs = mode.count.squeeze()\n",
    "category_conf = category_probs.copy()\n",
    "for conf in range(len(confidence_limits)):\n",
    "    category_conf[(category_probs < confidence_limits[conf][1]) & \\\n",
    "                  (category_probs >= confidence_limits[conf][0])] = conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week_category_preds[84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final['Country'] == 'Japan', last_week_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(category_conf, return_counts=True)\n",
    "print(np.int32(np.asarray((unique, counts)).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weeks_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get current UK-based travel advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_country_name_mapping = {\n",
    "    'Cabo Verde': 'Cape Verde',\n",
    "    'Bahamas, The': 'Bahamas',\n",
    "    'Congo, Rep.': 'Congo',\n",
    "    'Congo, Dem. Rep.': 'Democratic Republic of the Congo',\n",
    "    \"Cote d'Ivoire\": 'Cote d Ivoire',\n",
    "    'Korea, South': 'South Korea',\n",
    "    'Saint Kitts and Nevis': 'St Kitts and Nevis',\n",
    "    'Saint Lucia': 'St Lucia',\n",
    "    'Saint Vincent and the Grenadines': 'St Vincent and the Grenadines',\n",
    "    'United States': 'USA',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the list of countries which have specific travel advice.\n",
    "country_lst = df_final['Country'].drop_duplicates()\n",
    "responses = {}\n",
    "advice_urls = {}\n",
    "\n",
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "for country in country_lst:\n",
    "    formatted_name = country.lower().replace(' ', '-')\n",
    "    if country in travel_country_name_mapping:\n",
    "        formatted_name = travel_country_name_mapping[country].lower().replace(' ', '-')\n",
    "    new_url = f'{travel_advice_pre_url}/{formatted_name}'\n",
    "    req = requests.get(new_url, headers)\n",
    "    responses[country] = req\n",
    "    advice_urls[country] = new_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary of the advice.\n",
    "update_dates = {}\n",
    "summaries = {}\n",
    "summary_htmls = {}\n",
    "countries_no_advice = []\n",
    "removed_str = ['stay up to date', 'Find out how to return to', 'See ', 'Sign up ', 'Preparing for your return journey']\n",
    "early_break = False\n",
    "for country in country_lst:\n",
    "    req = responses[country]\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    start = soup.find('h1', class_='part-title', text=re.compile('Summary'))\n",
    "    if start is None:\n",
    "        continue\n",
    "    el = start.find_next_sibling(\"div\", class_='gem-c-govspeak govuk-govspeak direction-ltr')\n",
    "    div_stop = False\n",
    "    message_started = False\n",
    "    message = []\n",
    "    elements = []\n",
    "    for field in el.find_all():\n",
    "#         print(field)\n",
    "        if (field.name == 'div') and (len(message) > 0):\n",
    "            break\n",
    "        if field.name not in ['p', 'li']:\n",
    "            continue\n",
    "        if field.text is not None:\n",
    "#             text = field.text\n",
    "            text = field.text.replace('\\n', '')\n",
    "            if field.name == 'li':\n",
    "                text = '-' + text\n",
    "            if (text != 'FCDO') and ((len(message) == 0) or (message[-1] != text)):\n",
    "                if any([(x in text) for x in removed_str]):\n",
    "                    continue\n",
    "                if field.name == 'p':\n",
    "                    message_started = True\n",
    "                if message_started:\n",
    "                    message.append(text)\n",
    "                    elements.append(str(field))\n",
    "#     message = [(x + \".\\n\") if x[-1] not in ':.,;' else (x + '\\n') for x in message]\n",
    "    message = [(x + \". \") if x[-1] not in ':.,;' else (x + ' ') for x in message]\n",
    "    if len(message) == 0:\n",
    "        countries_no_advice.append(country)\n",
    "    message = \"\".join(message)\n",
    "    summaries[country] = message\n",
    "    summary_htmls[country] = elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_no_advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which country names are valid\n",
    "invalid = []\n",
    "for country in country_lst:\n",
    "    if responses[country].status_code != 200:\n",
    "        invalid.append(country)\n",
    "invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of exempted countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(travel_advice_url, headers)\n",
    "soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo_listed_countries = []\n",
    "exempt_words = {'coronavirus', 'travel', 'guidance', 'advice', 'england', 'scotland', 'wales', 'northern ireland'}\n",
    "start = soup.find('h2', id='countries-territories-and-regions-on-the-travel-corridor-list')\n",
    "for tr in start.find_next_siblings(\"ul\"):\n",
    "    # Get lists of countries\n",
    "    tds = tr.find_all(\"li\")\n",
    "    for td in tds:\n",
    "        for tl in td.find_all('a', class_=\"govuk-link\"):\n",
    "            name = tl.get_text()\n",
    "            if any([1 if x in name.lower() else 0 for x in exempt_words]):\n",
    "                continue\n",
    "            else:\n",
    "                fo_listed_countries.append(name.lower())\n",
    "fo_listed_countries = set(fo_listed_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and reconcile the two country lists\n",
    "allowed_countries = []\n",
    "for country in country_lst:\n",
    "    name = country\n",
    "    if country in travel_country_name_mapping:\n",
    "        name = travel_country_name_mapping[country]\n",
    "#     print(name)\n",
    "    if (name.lower() in fo_listed_countries) or (name.replace(' and', ' &').lower() in fo_listed_countries):\n",
    "        allowed_countries.append(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_lst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the following list to ensure its integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the following list and make sure we are not missing any important countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo_listed_countries - set([travel_country_name_mapping[x].lower() if x in travel_country_name_mapping else x.lower() for x in allowed_countries])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add these extra bits of info to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_last_week_category_preds = {}\n",
    "for itr, row in df_final.iterrows():\n",
    "    if row['is_country']:\n",
    "        country_last_week_category_preds[row['Country']] = last_week_category_preds[itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_advice = deepcopy(df_final[['Country']])\n",
    "df_advice['category'] = 1\n",
    "df_advice['advice_url'] = \"\"\n",
    "df_advice['summary'] = ''\n",
    "df_advice['last_week_predicted_category'] = 0\n",
    "df_advice['is_consistent'] = None\n",
    "\n",
    "for i, row in df_advice.iterrows():\n",
    "    if row['Country'] in allowed_countries:\n",
    "        df_advice.loc[i, 'category'] = 0\n",
    "    if row['Country'] in advice_urls:\n",
    "        df_advice.loc[i, 'advice_url'] = advice_urls[row['Country']]\n",
    "    if row['Country'] in summaries:\n",
    "        df_advice.loc[i, 'summary'] = summaries[row['Country']]\n",
    "    if country_last_week_category_preds[row['Country']] > 0:\n",
    "        df_advice.loc[i, 'last_week_predicted_category'] = 1\n",
    "df_advice.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare last week's category prediction to the current category.\n",
    "If they do not hold, then we shouldn't trust our predictions. Let's take note of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_advice[df_final['is_country'] == 1]\n",
    "consistent_countries = list(df_tmp[(df_tmp['category'] == 0) | (df_tmp['category'] == df_tmp['last_week_predicted_category'])]['Country'].values)\n",
    "for i, row in df_advice.iterrows():\n",
    "    if row['Country'] in consistent_countries:\n",
    "        df_advice.loc[i, 'is_consistent'] = 1\n",
    "    else:\n",
    "        df_advice.loc[i, 'is_consistent'] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {}\n",
    "fine_response = {}\n",
    "for itr in range(len(df_final)):\n",
    "    risk_vals = risk_preds[itr, :]\n",
    "    vals = category_preds[itr, :]\n",
    "    conf = category_conf[itr, :]\n",
    "    risk_vals = [int(x) for x in risk_vals]\n",
    "    vals = [int(x) for x in vals]\n",
    "    conf = [int(x) for x in conf]\n",
    "    country_response = {}\n",
    "    country_response[\"risk_preds\"] = risk_vals\n",
    "    \n",
    "    if df_final.loc[itr, 'is_country'] == 0:\n",
    "        country_response['lat'] = df_final.loc[itr, \"Lat\"]\n",
    "        country_response['lon'] = df_final.loc[itr, \"Lon\"]\n",
    "        country_response['ccode'] = df_final.loc[itr, 'CCODE']\n",
    "        country_response['country'] = df_final.loc[itr, 'Country']\n",
    "        country_response['graph_name'] = df_final.loc[itr, 'graph_name']\n",
    "        response[df_final.loc[itr, 'Name'] + ' ' + df_final.loc[itr, 'CCODE']] = country_response\n",
    "    else:\n",
    "        country_response[\"category\"] = int(df_advice.loc[itr, \"category\"]) * 2 # (2*)Necessary to align UK and US\n",
    "        if df_advice.loc[itr, 'is_consistent']:\n",
    "            country_response[\"summary\"] = df_advice.loc[itr, \"summary\"]\n",
    "            country_response[\"category_preds\"] = [x * 2 for x in vals] # (2*)Necessary to align UK and US\n",
    "        else:\n",
    "            country_response[\"summary\"] = '[CTP: Non-Covid factors may be at play. Check link for details.] ' + df_advice.loc[itr, \"summary\"]\n",
    "            country_response[\"category_preds\"] = [country_response[\"category\"] for x in vals]\n",
    "        country_response[\"confidence_preds\"] = conf\n",
    "        if df_final.loc[itr, 'CCODE'] == 'GBR':\n",
    "            country_response[\"advice_url\"] = 'N/A'\n",
    "        else:\n",
    "            country_response[\"advice_url\"] = df_advice.loc[itr, \"advice_url\"]\n",
    "        response[df_final.loc[itr, 'CCODE']] = country_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_folder}/response-UK.json', 'w') as json_file:\n",
    "    json.dump(response, json_file, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to the cloud\n",
    "blob = bucket.blob(f\"preds/weekly/{cur_week_name}/response-UK.json\")\n",
    "blob.upload_from_filename(f'{output_folder}/response-UK.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = set(df_final[df_final['CCODE'] == '-1']['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = set(df_final[df_final['CCODE'] != '-1']['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure is empty\n",
    "c1 - c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
