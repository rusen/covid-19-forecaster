{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the following environment variable is set! \n",
    "creds_path = os.environ['GOOGLE_APPLICATION_CREDENTIALS_PATH']\n",
    "gcs_client = storage.Client.from_service_account_json(creds_path)\n",
    "bucket = gcs_client.get_bucket('covid-19-forecaster-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_char_limit = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "begin_date_str = '1/27/20' # Make sure it's a monday, and the day before exists in the data\n",
    "begin_date = datetime.datetime.strptime(begin_date_str, \"%m/%d/%y\")\n",
    "\n",
    "today = datetime.date.today()\n",
    "today_date = f'{today.month}/{today.day}/{today.year-2000}'\n",
    "today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_names = {'UK': 'GBR', 'US': 'USA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "week_begin = today - datetime.timedelta(today.weekday())\n",
    "week_end = week_begin + datetime.timedelta(days=6)\n",
    "cur_week_name = f'{week_begin.month}-{week_begin.day}-{week_begin.year-2000}-to-{week_end.month}-{week_end.day}-{week_end.year-2000}'\n",
    "preds_folder = f'./preds/weekly/{cur_week_name}'\n",
    "output_folder = f'./output/weekly/{cur_week_name}'\n",
    "print(f'Current identifier: *{cur_week_name}*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses\n",
    "responses = {}\n",
    "for name in response_names:\n",
    "    print(name)\n",
    "    with open(f'{preds_folder}/response-{name}.json') as json_file: \n",
    "        responses[name] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_keys = set(responses['UK'].keys()) & set(responses['US'].keys())\n",
    "len(joint_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create countries response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_response = {}\n",
    "country_keys = [x for x in joint_keys if len(x) == 3]\n",
    "joint_fields = ['risk_preds']\n",
    "# country_fields = ['category', 'advice_url', 'summary', 'category_preds', 'confidence_preds']\n",
    "country_fields = ['category', 'advice_url', 'summary', 'category_preds']\n",
    "for key in country_keys:\n",
    "    country_response[key] = {}\n",
    "    \n",
    "    # Get common fields first\n",
    "    for field in joint_fields:\n",
    "        if field in responses['UK'][key]:\n",
    "            country_response[key][field] = responses['UK'][key][field]\n",
    "\n",
    "    for field in country_fields:\n",
    "        if field not in responses['UK'][key]:\n",
    "            continue\n",
    "        country_response[key][field] = {}\n",
    "        for name in response_names:\n",
    "            if field == 'summary':\n",
    "                country_response[key][field][response_names[name]] = responses[name][key][field][:summary_char_limit]\n",
    "            else:\n",
    "                country_response[key][field][response_names[name]] = responses[name][key][field]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Regional response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_response = []\n",
    "region_keys = [x for x in joint_keys if len(x) > 3]\n",
    "joint_fields = ['risk_preds']\n",
    "region_fields = ['lat', 'lon', 'ccode', 'graph_name']\n",
    "for key in region_keys:\n",
    "    new_response = {'name': key[:-4], 'country': responses['UK'][key]['country']}\n",
    "    \n",
    "    # Get common fields first\n",
    "    for field in joint_fields:\n",
    "        if field in responses['UK'][key]:\n",
    "            new_response[field] = responses['UK'][key][field]\n",
    "    \n",
    "    # Get region fields (they happen to be the shared ones)\n",
    "    for field in region_fields:\n",
    "        if field in responses['UK'][key]:\n",
    "            new_response[field] = responses['UK'][key][field]\n",
    "    region_response.append(new_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_updated_txt = datetime.datetime.utcnow().strftime(\"last updated: %Y-%m-%d at %H:%M:%S (UTC)\")\n",
    "last_updated_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_response = {'last_updated': last_updated_txt, 'data': country_response}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, upload results to this week's folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload country json to current week's folder\n",
    "with open(f'{preds_folder}/countries.json', 'w') as json_file:\n",
    "    json.dump(main_response, json_file, indent='\\t')\n",
    "blob = bucket.blob(f\"preds/weekly/{cur_week_name}/countries.json\")\n",
    "blob.upload_from_filename(f'{preds_folder}/countries.json')\n",
    "\n",
    "# Upload region json to current week's folder\n",
    "with open(f'{preds_folder}/regions.json', 'w') as json_file:\n",
    "    json.dump(region_response, json_file, indent='\\t')\n",
    "blob = bucket.blob(f\"preds/weekly/{cur_week_name}/regions.json\")\n",
    "blob.upload_from_filename(f'{preds_folder}/regions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the output folder of this week to azure as well.\n",
    "\n",
    "# Delete this week's output if it's up there\n",
    "blobs = bucket.list_blobs(prefix=f\"output/weekly/{cur_week_name}\")\n",
    "for blob in blobs:\n",
    "    blob.delete()\n",
    "    \n",
    "# Upload the files\n",
    "for path, subdirs, files in os.walk(output_folder):\n",
    "    path = path.replace(\"\\\\\",\"/\")\n",
    "    directory_name = path.replace(output_folder, f\"output/weekly/{cur_week_name}\")\n",
    "    for file in files:\n",
    "        blob = bucket.blob(directory_name+'/'+file)\n",
    "        blob.upload_from_filename(os.path.join(path, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally upload the response jsons to the public \"current\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload country json to public folder\n",
    "with open(f'{preds_folder}/countries.json', 'w') as json_file:\n",
    "    json.dump(main_response, json_file, indent='\\t')\n",
    "blob = bucket.blob(f\"preds/weekly/current/countries.json\")\n",
    "blob.upload_from_filename(f'{preds_folder}/countries.json')\n",
    "blob.make_public() # BE CAREFUL\n",
    "\n",
    "# Upload region json to public folder\n",
    "with open(f'{preds_folder}/regions.json', 'w') as json_file:\n",
    "    json.dump(region_response, json_file, indent='\\t')\n",
    "blob = bucket.blob(f\"preds/weekly/current/regions.json\")\n",
    "blob.upload_from_filename(f'{preds_folder}/regions.json')\n",
    "blob.make_public() # BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{preds_folder}/countries.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
