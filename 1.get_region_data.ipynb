{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded paths\n",
    "# population_csv = './data/population/data/population.csv'\n",
    "daily_reports_path = './data/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports'\n",
    "us_meta = './US_state_pop_coords.csv'\n",
    "us_df_path = './data/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = pd.read_csv(us_df_path)\n",
    "df_us = df_us.rename(columns={'Province_State': 'State'})\n",
    "df_us = df_us.drop(columns=['Lat', 'Long_'])\n",
    "df_us_meta = pd.read_csv(us_meta)\n",
    "df_us = df_us.merge(df_us_meta, on='State')\n",
    "df_us = df_us.rename(columns={'State': 'Region'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important dates\n",
    "begin_date_str = '1/27/20' # Make sure it's a monday, and the day before exists in the data\n",
    "begin_date = datetime.datetime.strptime(begin_date_str, \"%m/%d/%y\").date()\n",
    "print(f'Begin date : {begin_date_str}')\n",
    "\n",
    "today = datetime.date.today()\n",
    "today_date = f'{today.month}/{today.day}/{today.year-2000}'\n",
    "print(f'Date today : {today_date}')\n",
    "\n",
    "end_date = today - datetime.timedelta(today.weekday()+1)\n",
    "end_date = f'{end_date.month}/{end_date.day}/{end_date.year-2000}'\n",
    "print(f'End of last week : {end_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "week_begin = today - datetime.timedelta(today.weekday())\n",
    "week_end = week_begin + datetime.timedelta(days=6)\n",
    "cur_week_name = f'{week_begin.month}-{week_begin.day}-{week_begin.year-2000}-to-{week_end.month}-{week_end.day}-{week_end.year-2000}'\n",
    "output_folder = f'./output/weekly/{cur_week_name}'\n",
    "print(f'Current identifier: *{cur_week_name}*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_date = begin_date\n",
    "df = None\n",
    "daily_cols = []\n",
    "us_daily_cols = []\n",
    "coords = {}\n",
    "prev_df_daily = None\n",
    "\n",
    "while cur_date < today:\n",
    "    cur_date_str = cur_date.strftime('%m-%d-%Y')\n",
    "    cur_date_str_no_padding = cur_date.strftime('%m/%d/%y').lstrip(\"0\").replace(\"/0\", \"/\")\n",
    "    cur_date += datetime.timedelta(1)\n",
    "    print(cur_date_str_no_padding)\n",
    "    daily_report = f'{daily_reports_path}/{cur_date_str}.csv'\n",
    "    if (not os.path.exists(daily_report)) or (cur_date_str_no_padding not in df_us.columns):\n",
    "        break\n",
    "    us_daily_cols.append(cur_date_str_no_padding)\n",
    "        \n",
    "    df_daily_org = pd.read_csv(daily_report)\n",
    "    if ('Combined_Key' not in df_daily_org) or \\\n",
    "       ('Lat' not in df_daily_org) or \\\n",
    "       ('Long_' not in df_daily_org) or \\\n",
    "       ('Incidence_Rate' not in df_daily_org):\n",
    "        continue\n",
    "        \n",
    "    df_daily_org['Lat'] = np.round(df_daily_org['Lat'],3)\n",
    "    df_daily_org['Lon'] = np.round(df_daily_org['Long_'],3)\n",
    "\n",
    "    df_daily = df_daily_org[['Province_State', 'Country_Region', 'Combined_Key', 'Lat', 'Lon', 'Incidence_Rate']]\n",
    "    \n",
    "    # Save\n",
    "    df_daily = df_daily.rename(columns={'Incidence_Rate': cur_date_str_no_padding})\n",
    "    daily_cols.append(cur_date_str_no_padding)\n",
    "    if df is None:\n",
    "        df = deepcopy(df_daily)\n",
    "    else:\n",
    "        df = df.merge(df_daily, on=['Province_State', 'Country_Region', 'Lat', 'Lon', 'Combined_Key'], how='outer')\n",
    "# week_begin = today - datetime.timedelta(today.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "last_weeks_valid = 10\n",
    "df_clean = deepcopy(df)\n",
    "print(len(df_clean))\n",
    "df_clean = df_clean[~df_clean['Province_State'].isna()]\n",
    "print('After None name cleaning:', len(df_clean))\n",
    "df_clean = df_clean[~np.isnan(df_clean[daily_cols[-(7 * last_weeks_valid):]].values).any(axis=1)]\n",
    "print('After None value cleaning:', len(df_clean))\n",
    "df_clean = df_clean[df_clean['Country_Region'] != 'US']\n",
    "print('After US city cleaning:', len(df_clean))\n",
    "\n",
    "df_clean = df_clean.rename(columns={'Province_State': 'Region', 'Country_Region': 'Country'})\n",
    "\n",
    "# Calculate daily incidence rate, remove first date\n",
    "df_clean_org = deepcopy(df_clean)\n",
    "for itr in range(1, len(daily_cols)):\n",
    "    # Get the difference from the previous day\n",
    "    df_clean[daily_cols[itr]] = (df_clean_org[daily_cols[itr]] - df_clean_org[daily_cols[itr-1]]) / 100000.0\n",
    "df_clean = df_clean.drop(columns=[daily_cols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_cases = df_us.groupby('Region').sum()[us_daily_cols].reset_index()\n",
    "df_us_meta_full = deepcopy(df_us_meta)\n",
    "df_us_meta_full = df_us_meta_full.rename(columns={'State': 'Region'})\n",
    "df_us_meta_full['Country'] = 'United States'\n",
    "df_us_meta_full['Combined_Key'] = df_us_meta_full['Region'] + ', ' + df_us_meta_full['Country']\n",
    "state_df = df_us_meta_full.merge(state_cases, on='Region')\n",
    "state_df['Lat'] = np.round(state_df['Lat'],3)\n",
    "state_df['Lon'] = np.round(state_df['Lon'],3)\n",
    "state_df_org = deepcopy(state_df)\n",
    "for itr in range(1, len(us_daily_cols)):\n",
    "    state_df[us_daily_cols[itr]] = (state_df_org[us_daily_cols[itr]] - state_df_org[us_daily_cols[itr-1]]) / state_df['Population']\n",
    "state_df = state_df.drop(columns=['Population', us_daily_cols[0]])\n",
    "state_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_meta_full['Combined_Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = list(set(state_df.columns) & set(df_clean.columns))\n",
    "all_region_df = state_df.merge(df_clean, on=list(set(state_df.columns) & set(df_clean.columns)), how='outer')\n",
    "all_region_df['CCODE'] = -1\n",
    "all_region_df['is_country'] = 0\n",
    "all_region_df = all_region_df[['Region', 'Country', 'is_country', 'CCODE', 'Combined_Key', 'Lat', 'Lon'] + us_daily_cols[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_df = all_region_df.rename(columns={'Region': 'Name'})\n",
    "all_region_df = all_region_df.drop(columns=['Combined_Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_df = all_region_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_region_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_df.to_csv(f'{output_folder}/all_region_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
